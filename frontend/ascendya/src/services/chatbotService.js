import { GoogleGenerativeAI } from "@google/generative-ai";

const genAI = new GoogleGenerativeAI(import.meta.env.VITE_GEMINI_API_KEY);

// Contexto del asistente virtual
const ASSISTANT_CONTEXT = `
Eres un asistente virtual especializado en educaci√≥n y mentor acad√©mico llamado "Ascend AI". 
Tu funci√≥n es ayudar a estudiantes que se preparan para ex√°menes de admisi√≥n universitaria y su desarrollo acad√©mico.

CARACTER√çSTICAS:
- Eres amigable, motivador y profesional
- Proporcionas respuestas claras y estructuradas
- Te enfocas en educaci√≥n, estudio y desarrollo personal
- Puedes analizar documentos acad√©micos cuando se adjunten
- Ofreces consejos de estudio personalizados
- Ayudas con dudas espec√≠ficas de materias

CAPACIDADES:
- Responder preguntas sobre materias acad√©micas
- Crear planes de estudio personalizados
- Analizar documentos y archivos acad√©micos
- Proporcionar t√©cnicas de estudio
- Dar consejos motivacionales
- Explicar conceptos complejos de forma simple

REGLAS:
- Siempre mant√©n un tono positivo y motivador
- Si no sabes algo espec√≠fico, recon√≥celo honestamente
- Sugiere recursos adicionales cuando sea apropiado
- Enf√≥cate en el aprendizaje efectivo
- Personaliza tus respuestas seg√∫n el contexto del usuario

Responde en espa√±ol de manera conversacional y √∫til.
`;

export const getChatbotResponse = async (
  message,
  conversationHistory = [],
  attachedFile = null
) => {
  try {
    const model = genAI.getGenerativeModel({ model: "gemini-1.5-flash" });

    // Construir el historial de conversaci√≥n
    let conversationText = "";
    if (conversationHistory.length > 0) {
      conversationText =
        "\n\nHistorial de conversaci√≥n:\n" +
        conversationHistory
          .map((msg) => `${msg.role}: ${msg.content}`)
          .join("\n");
    }

    let prompt = `${ASSISTANT_CONTEXT}${conversationText}\n\nUsuario: ${message}`;

    let result;

    // Si hay un archivo adjunto, procesarlo
    if (attachedFile) {
      const fileText = await readFileAsText(attachedFile);
      prompt += `\n\nArchivo adjunto (${attachedFile.name}):\n${fileText}`;
    }

    result = await model.generateContent(prompt);
    const response = await result.response;
    const text = response.text();

    return {
      success: true,
      response: text,
      timestamp: new Date().toISOString(),
    };
  } catch (error) {
    console.error("Error en chatbot service:", error);
    return {
      success: false,
      error: error.message || "Error al conectar con el asistente",
      timestamp: new Date().toISOString(),
    };
  }
};

// Funci√≥n para leer archivos como texto
const readFileAsText = (file) => {
  return new Promise((resolve, reject) => {
    const reader = new FileReader();

    reader.onload = (e) => {
      resolve(e.target.result);
    };

    reader.onerror = (e) => {
      reject(new Error("Error al leer el archivo"));
    };

    // Leer seg√∫n el tipo de archivo
    if (
      file.type.startsWith("text/") ||
      file.name.endsWith(".txt") ||
      file.name.endsWith(".md") ||
      file.name.endsWith(".json")
    ) {
      reader.readAsText(file);
    } else if (file.type === "application/pdf") {
      resolve(
        "Archivo PDF detectado. Por favor, convierte el contenido a texto para un mejor an√°lisis."
      );
    } else {
      resolve(`Archivo ${file.name} adjuntado. Tipo: ${file.type}`);
    }
  });
};

// Funci√≥n para convertir voz a texto usando Web Speech API
export const startVoiceRecognition = (onResult, onError, onStart = null) => {
  if (
    !("webkitSpeechRecognition" in window) &&
    !("SpeechRecognition" in window)
  ) {
    onError(
      "Tu navegador no soporta reconocimiento de voz. Puedes escribir tu mensaje en el chat."
    );
    return null;
  }

  const SpeechRecognition =
    window.SpeechRecognition || window.webkitSpeechRecognition;
  const recognition = new SpeechRecognition();

  // Configuraci√≥n mejorada para evitar problemas de red
  recognition.continuous = false;
  recognition.interimResults = false;
  recognition.lang = "es-ES";
  recognition.maxAlternatives = 1;

  // Intentar configurar para uso offline/local
  try {
    if ("webkitSpeechRecognition" in window) {
      // Configuraciones espec√≠ficas para Chrome/Edge
      recognition.serviceURI = ""; // Vac√≠o para forzar local
      recognition.grammars = null; // Sin gram√°ticas espec√≠ficas
    }
  } catch (e) {
    console.log(
      "No se pudo configurar para uso local, usando configuraci√≥n est√°ndar"
    );
  }

  recognition.onstart = () => {
    console.log("Reconocimiento de voz iniciado");
    if (onStart) onStart();
  };

  recognition.onresult = (event) => {
    if (event.results && event.results.length > 0) {
      const transcript = event.results[0][0].transcript;
      console.log("Transcripci√≥n obtenida:", transcript);
      onResult(transcript);
    } else {
      onError(
        "No se pudo capturar ning√∫n audio. Intenta hablar m√°s cerca del micr√≥fono."
      );
    }
  };

  recognition.onerror = (event) => {
    console.error("Error de reconocimiento de voz:", event.error);

    let errorMessage = "Error en el reconocimiento de voz";

    switch (event.error) {
      case "network":
        errorMessage =
          "üåê Problema de conexi√≥n detectado. El reconocimiento de voz requiere internet estable. Mientras tanto, puedes escribir tu mensaje en el chat.";
        // Sugerir reintentar despu√©s de un momento
        setTimeout(() => {
          onError(
            "üí° Consejo: Verifica tu conexi√≥n WiFi o datos m√≥viles y vuelve a intentar el reconocimiento de voz."
          );
        }, 3000);
        break;
      case "not-allowed":
        errorMessage =
          "üé§ Permiso de micr√≥fono denegado. Ve a la configuraci√≥n de tu navegador ‚Üí Privacidad ‚Üí Micr√≥fono y permite el acceso para este sitio.";
        break;
      case "no-speech":
        errorMessage =
          "üîá No se detect√≥ ning√∫n audio. Aseg√∫rate de hablar cerca del micr√≥fono y que no haya ruido de fondo.";
        break;
        "No se detect√≥ ning√∫n audio. Aseg√∫rate de hablar cerca del micr√≥fono.";
        break;
      case "audio-capture":
        errorMessage =
          "No se pudo capturar audio. Verifica que tu micr√≥fono est√© funcionando.";
        break;
      case "service-not-allowed":
        errorMessage =
          "El servicio de reconocimiento de voz no est√° disponible.";
        break;
      case "bad-grammar":
        errorMessage =
          "Error en el procesamiento del audio. Intenta hablar m√°s claro.";
        break;
      case "language-not-supported":
        errorMessage = "El idioma espa√±ol no est√° soportado en este navegador.";
        break;
      default:
        errorMessage = `Error de reconocimiento: ${event.error}. Puedes escribir tu mensaje en el chat.`;
    }

    onError(errorMessage);
  };

  recognition.onend = () => {
    console.log("Reconocimiento de voz terminado");
  };

  // Agregar timeout para evitar que se quede colgado
  const timeout = setTimeout(() => {
    try {
      recognition.stop();
      onError(
        "Timeout: El reconocimiento de voz tard√≥ demasiado. Intenta de nuevo."
      );
    } catch (e) {
      console.log("Recognition already stopped");
    }
  }, 10000); // 10 segundos timeout

  // Limpiar timeout cuando termine
  recognition.onend = () => {
    clearTimeout(timeout);
    console.log("Reconocimiento de voz terminado");
  };

  recognition.onresult = (event) => {
    clearTimeout(timeout);
    if (event.results && event.results.length > 0) {
      const transcript = event.results[0][0].transcript;
      console.log("Transcripci√≥n obtenida:", transcript);
      onResult(transcript);
    } else {
      onError(
        "No se pudo capturar ning√∫n audio. Intenta hablar m√°s cerca del micr√≥fono."
      );
    }
  };

  return recognition;
};

// Funci√≥n de reintentos para reconocimiento de voz
export const startVoiceRecognitionWithRetry = (
  onResult,
  onError,
  onStart = null,
  maxRetries = 2
) => {
  let retryCount = 0;

  const attemptRecognition = () => {
    const recognition = startVoiceRecognition(
      onResult,
      (error) => {
        // Si es un error de red y a√∫n tenemos reintentos
        if (error.includes("conexi√≥n") && retryCount < maxRetries) {
          retryCount++;
          onError(
            `üîÑ Reintentando reconocimiento de voz... (${retryCount}/${maxRetries})`
          );
          setTimeout(() => {
            attemptRecognition();
          }, 2000);
        } else {
          // Si no es error de red o ya no hay m√°s reintentos
          onError(error);
        }
      },
      onStart
    );

    return recognition;
  };

  return attemptRecognition();
};

// Funci√≥n alternativa para entrada de voz con fallback manual
export const createVoiceInputFallback = (onResult) => {
  return {
    startManualInput: () => {
      const transcript = prompt(
        "üé§ Como el reconocimiento autom√°tico fall√≥, puedes escribir aqu√≠ lo que quer√≠as decir por voz:"
      );
      if (transcript && transcript.trim()) {
        onResult(transcript.trim());
        return true;
      }
      return false;
    },

    showVoiceInstructions: () => {
      return `
üéôÔ∏è **Gu√≠a para Solucionar Problemas de Voz:**

1. **Verifica tu conexi√≥n a internet** - El reconocimiento necesita conexi√≥n estable
2. **Permite permisos de micr√≥fono** - Busca el √≠cono üé§ en la barra de direcciones
3. **Usa Chrome o Edge** - Mejor compatibilidad con reconocimiento de voz
4. **Habla claramente** - A unos 15cm del micr√≥fono
5. **Evita ruido de fondo** - Busca un lugar silencioso

üí° **Alternativa:** Puedes escribir tu mensaje directamente en el chat.
      `;
    },
  };
};

// Funci√≥n para verificar permisos y disponibilidad del micr√≥fono
export const checkMicrophonePermissions = async () => {
  try {
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    // Cerrar el stream inmediatamente despu√©s de verificar
    stream.getTracks().forEach((track) => track.stop());
    return { success: true, message: "Micr√≥fono disponible" };
  } catch (error) {
    let message = "Error al acceder al micr√≥fono";

    switch (error.name) {
      case "NotAllowedError":
        message =
          "Permiso de micr√≥fono denegado. Por favor, permite el acceso en la configuraci√≥n del navegador.";
        break;
      case "NotFoundError":
        message =
          "No se encontr√≥ ning√∫n micr√≥fono. Verifica que tengas uno conectado.";
        break;
      case "NotReadableError":
        message = "El micr√≥fono est√° siendo usado por otra aplicaci√≥n.";
        break;
      case "OverconstrainedError":
        message =
          "No se pudo configurar el micr√≥fono con los par√°metros solicitados.";
        break;
      default:
        message = `Error del micr√≥fono: ${error.message}`;
    }

    return { success: false, message };
  }
};

// Funci√≥n para verificar conectividad de red
export const checkNetworkConnectivity = () => {
  return new Promise((resolve) => {
    if (!navigator.onLine) {
      resolve({ success: false, message: "Sin conexi√≥n a internet" });
      return;
    }

    // Hacer una peque√±a prueba de conectividad
    const img = new Image();
    const timeout = setTimeout(() => {
      resolve({ success: false, message: "Conexi√≥n lenta o inestable" });
    }, 5000);

    img.onload = () => {
      clearTimeout(timeout);
      resolve({ success: true, message: "Conexi√≥n estable" });
    };

    img.onerror = () => {
      clearTimeout(timeout);
      resolve({ success: false, message: "Problemas de conectividad" });
    };

    // Usar un pixel de Google para verificar conectividad
    img.src = "https://www.google.com/favicon.ico?" + Date.now();
  });
};

// Funci√≥n para texto a voz
export const speakText = (text) => {
  if ("speechSynthesis" in window) {
    const utterance = new SpeechSynthesisUtterance(text);
    utterance.lang = "es-ES";
    utterance.rate = 0.9;
    utterance.pitch = 1;

    window.speechSynthesis.speak(utterance);
  }
};
